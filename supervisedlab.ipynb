{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b4574b-63a1-4a03-b2d5-968666f566e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n",
      "\n",
      "Columns with missing values:\n",
      "id          False\n",
      "age         False\n",
      "sex         False\n",
      "dataset     False\n",
      "cp          False\n",
      "trestbps     True\n",
      "chol         True\n",
      "fbs          True\n",
      "restecg      True\n",
      "thalch       True\n",
      "exang        True\n",
      "oldpeak      True\n",
      "slope        True\n",
      "ca           True\n",
      "thal         True\n",
      "num         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV file into a DataFrame (replace 'your_dataset.csv' with your actual file path)\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "\n",
    "# 1. Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# 2. Display general information about the dataset (non-null counts)\n",
    "df.info()\n",
    "\n",
    "# 3. Check if any column contains missing values\n",
    "missing_any = df.isnull().any()\n",
    "print(\"\\nColumns with missing values:\")\n",
    "print(missing_any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39afb224-27d0-4924-892b-70e9b5021840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
      "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
      "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
      "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
      "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
      "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
      "\n",
      "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
      "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
      "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
      "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
      "3          normal   187.0  False      3.5  downsloping  0.0   \n",
      "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
      "\n",
      "                thal  num  \n",
      "0       fixed defect    0  \n",
      "1             normal    2  \n",
      "2  reversable defect    1  \n",
      "3             normal    0  \n",
      "4             normal    0  \n",
      "\n",
      "Checking for Missing Values:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 5: If there are missing values, apply different imputation methods\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 5.1 Mean Imputation\u001b[39;00m\n\u001b[0;32m     19\u001b[0m df_mean_imputation \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 20\u001b[0m df_mean_imputation\u001b[38;5;241m.\u001b[39mfillna(\u001b[43mdf_mean_imputation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataset after Mean Imputation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_mean_imputation\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11693\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11685\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11691\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11692\u001b[0m ):\n\u001b[1;32m> 11693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11695\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "\n",
    "# Step 3: Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 4: Check for missing values in the dataset\n",
    "print(\"\\nChecking for Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Step 5: If there are missing values, apply different imputation methods\n",
    "\n",
    "# 5.1 Mean Imputation\n",
    "df_mean_imputation = df.copy()\n",
    "df_mean_imputation.fillna(df_mean_imputation.mean(), inplace=True)\n",
    "print(\"\\nDataset after Mean Imputation:\")\n",
    "print(df_mean_imputation.head())\n",
    "\n",
    "# 5.2 Median Imputation\n",
    "df_median_imputation = df.copy()\n",
    "df_median_imputation.fillna(df_median_imputation.median(), inplace=True)\n",
    "print(\"\\nDataset after Median Imputation:\")\n",
    "print(df_median_imputation.head())\n",
    "\n",
    "# 5.3 Mode Imputation (for categorical columns if present)\n",
    "df_mode_imputation = df.copy()\n",
    "df_mode_imputation.fillna(df_mode_imputation.mode().iloc[0], inplace=True)\n",
    "print(\"\\nDataset after Mode Imputation:\")\n",
    "print(df_mode_imputation.head())\n",
    "\n",
    "# 5.4 Dropping rows with missing values (if preferred)\n",
    "df_dropna = df.dropna()\n",
    "print(\"\\nDataset after Dropping rows with missing values:\")\n",
    "print(df_dropna.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441ca8a0-1880-4fbc-898a-22cea5e35e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
      "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
      "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
      "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
      "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
      "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
      "\n",
      "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
      "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
      "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
      "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
      "3          normal   187.0  False      3.5  downsloping  0.0   \n",
      "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
      "\n",
      "                thal  num  \n",
      "0       fixed defect    0  \n",
      "1             normal    2  \n",
      "2  reversable defect    1  \n",
      "3             normal    0  \n",
      "4             normal    0  \n",
      "\n",
      "Summary of Missing Values in the Dataset:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after Mean Imputation:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after Median Imputation:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after Mode Imputation:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs           0\n",
      "restecg       0\n",
      "thalch       55\n",
      "exang         0\n",
      "oldpeak      62\n",
      "slope         0\n",
      "ca          611\n",
      "thal          0\n",
      "num           0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after Forward Fill:\n",
      "id          0\n",
      "age         0\n",
      "sex         0\n",
      "dataset     0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "num         0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after Backward Fill:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps      0\n",
      "chol          0\n",
      "fbs           0\n",
      "restecg       0\n",
      "thalch        0\n",
      "exang         0\n",
      "oldpeak       0\n",
      "slope         7\n",
      "ca          160\n",
      "thal          2\n",
      "num           0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after Dropping Rows with Missing Values:\n",
      "id          0\n",
      "age         0\n",
      "sex         0\n",
      "dataset     0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "num         0\n",
      "dtype: int64\n",
      "\n",
      "Original Dataset after Dropping Rows:\n",
      "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
      "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
      "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
      "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
      "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
      "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
      "\n",
      "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
      "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
      "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
      "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
      "3          normal   187.0  False      3.5  downsloping  0.0   \n",
      "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
      "\n",
      "                thal  num  \n",
      "0       fixed defect    0  \n",
      "1             normal    2  \n",
      "2  reversable defect    1  \n",
      "3             normal    0  \n",
      "4             normal    0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mean_imputation[numeric_cols].fillna(df_mean_imputation[numeric_cols].mean(), inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_median_imputation[numeric_cols].fillna(df_median_imputation[numeric_cols].median(), inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_mode_imputation[col].fillna(df_mode_imputation[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:36: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_mode_imputation[col].fillna(df_mode_imputation[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:45: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffill.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:45: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_ffill.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:52: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_bfill.fillna(method='bfill', inplace=True)\n",
      "C:\\Users\\Galaxyz\\AppData\\Local\\Temp\\ipykernel_11388\\1290960558.py:52: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_bfill.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the heart_disease_uci dataset\n",
    "# Assuming the file is in the same directory, if not, provide the correct path\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "\n",
    "# Step 2: Display the first few rows and check for missing values\n",
    "print(\"Original Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nSummary of Missing Values in the Dataset:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 3: Handling missing data using different imputation methods\n",
    "\n",
    "# 3.1 Mean Imputation (for numeric columns)\n",
    "df_mean_imputation = df.copy()\n",
    "numeric_cols = df_mean_imputation.select_dtypes(include=['number']).columns\n",
    "df_mean_imputation[numeric_cols].fillna(df_mean_imputation[numeric_cols].mean(), inplace=True)\n",
    "\n",
    "print(\"\\nDataset after Mean Imputation:\")\n",
    "print(df_mean_imputation.isnull().sum())  # Check if missing values are filled\n",
    "\n",
    "# 3.2 Median Imputation (for numeric columns)\n",
    "df_median_imputation = df.copy()\n",
    "df_median_imputation[numeric_cols].fillna(df_median_imputation[numeric_cols].median(), inplace=True)\n",
    "\n",
    "print(\"\\nDataset after Median Imputation:\")\n",
    "print(df_median_imputation.isnull().sum())  # Check if missing values are filled\n",
    "\n",
    "# 3.3 Mode Imputation (for categorical columns)\n",
    "df_mode_imputation = df.copy()\n",
    "categorical_cols = df_mode_imputation.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df_mode_imputation[col].fillna(df_mode_imputation[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"\\nDataset after Mode Imputation:\")\n",
    "print(df_mode_imputation.isnull().sum())  # Check if missing values are filled\n",
    "\n",
    "# Step 4: Other Imputation Techniques\n",
    "\n",
    "# 4.1 Forward Fill (Fill missing values with the last known value)\n",
    "df_ffill = df.copy()\n",
    "df_ffill.fillna(method='ffill', inplace=True)\n",
    "\n",
    "print(\"\\nDataset after Forward Fill:\")\n",
    "print(df_ffill.isnull().sum())  # Check if missing values are filled\n",
    "\n",
    "# 4.2 Backward Fill (Fill missing values with the next known value)\n",
    "df_bfill = df.copy()\n",
    "df_bfill.fillna(method='bfill', inplace=True)\n",
    "\n",
    "print(\"\\nDataset after Backward Fill:\")\n",
    "print(df_bfill.isnull().sum())  # Check if missing values are filled\n",
    "\n",
    "# Step 5: Dropping rows with missing data (if imputation isn't preferred)\n",
    "df_dropped = df.copy()\n",
    "df_dropped.dropna(inplace=True)\n",
    "\n",
    "print(\"\\nDataset after Dropping Rows with Missing Values:\")\n",
    "print(df_dropped.isnull().sum())  # Check if missing values are filled\n",
    "\n",
    "print(\"\\nOriginal Dataset after Dropping Rows:\")\n",
    "print(df_dropped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99b900-7aef-4c2d-b462-8e59093d440f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
